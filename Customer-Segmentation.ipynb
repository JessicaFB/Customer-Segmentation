{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-Packages-+-Data\" data-toc-modified-id=\"Import-Packages-+-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import Packages + Data</a></span></li><li><span><a href=\"#Explore-+-Clean-Data\" data-toc-modified-id=\"Explore-+-Clean-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Explore + Clean Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Check-For-Null-Values\" data-toc-modified-id=\"Check-For-Null-Values-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Check For Null Values</a></span></li><li><span><a href=\"#Check-For-Duplicates\" data-toc-modified-id=\"Check-For-Duplicates-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Check For Duplicates</a></span></li><li><span><a href=\"#Add-TotalPrice-Column\" data-toc-modified-id=\"Add-TotalPrice-Column-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Add TotalPrice Column</a></span></li><li><span><a href=\"#Remove-Outliers\" data-toc-modified-id=\"Remove-Outliers-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Remove Outliers</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages + Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data & convert to df\n",
    "data = pd.read_excel('Data/Online_Retail.xlsx')\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Preview\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here there are multiple items and quantities purchased on each invoice. I will create another column that shows total spent on each item, so Quantity * UnitPrice. That way we can group by invoice number, customer, etc. and see the total they spent per invoice and item.\n",
    "\n",
    "We're also going to be adding Recency, Frequency and Monetary columns so we can conduct an RMF analysis and segment customers that way as well. \n",
    "\n",
    "Let's take a look at some of the basics before we hop into it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore + Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**InvoiceNo** is currently an object. I'm going to change that to an integer so we'll be able to group by invoice number. \n",
    "\n",
    "**StockCode** can stay an object, I'm guessing it's a string. \n",
    "\n",
    "It's great that **InvoiceDate** is already in datetime format, because we can peak at some time series in the EDA to see if we can collect any further insights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check For Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we have a good amount of Null values for **CustomerID** and **Description**. Let's see how much of the total this accounts for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description\n",
    "print('Description Percent Null Values:')\n",
    "print(f\"{((df.Description.isnull().sum())/len(df.Description)*100).round(4)} % \\n\")\n",
    "\n",
    "# CustomerID\n",
    "print('CustomerID Percent Null Values:')\n",
    "print(f\"{((df.CustomerID.isnull().sum())/len(df.CustomerID)*100).round(4)} % \\n\")\n",
    "\n",
    "print('==============================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of missing values for the **Description** column is small, however for the **CustomerID** column it is large at almost 25%. I'm curious how many customers there were. Let's take a look at the number of unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique CustomerIDs\n",
    "\n",
    "print(f'No. of unique CustomerIDs: \\n{len(df.CustomerID.value_counts())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we still have data from over 4,300 customers, and we don't have any way of identifying the customers with the Null **CustomerID** field, it only makes sense to remove them. And since the number of Null **Description** fields are low, we will remove those as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows w/null fields\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check For Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df.duplicated()]\n",
    "df[df.InvoiceNo == 536412].duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[617:622]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of these seem to be duplicates, so we're going to leave these here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add TotalPrice Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TotalPrice'] = df['Quantity'] * df['UnitPrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.TotalPrice.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there are some major outliers in our dataset. Let's remove them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentiles for Quantity\n",
    "\n",
    "# Define percentiles\n",
    "percentiles = [0,2.5,97.5,100]\n",
    "\n",
    "# Print them out\n",
    "for i in percentiles:\n",
    "    q = i/100\n",
    "    print(\"{} percentile Quantity: {}\".format(q, df.Quantity.quantile(q=q)))\n",
    "    \n",
    "# Percentiles for UnitPrice\n",
    "\n",
    "# Print them out\n",
    "for i in percentiles:\n",
    "    q = i/100\n",
    "    print(\"{} percentile UnitPrice: {}\".format(q, df.UnitPrice.quantile(q=q)))\n",
    "    \n",
    "# Percentiles for TotalPrice\n",
    "\n",
    "# Print them out\n",
    "for i in percentiles:\n",
    "    q = i/100\n",
    "    print(\"{} percentile TotalPrice: {}\".format(q, df.TotalPrice.quantile(q=q)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to remove what may be returns or negative **Quantity** values as the lower 1% is -2.0 and the lower 2.5% was 1.0. We also removed all of the negative UnitPrice values when we removed the Null **CustomerID** values. \n",
    "\n",
    "We're also going to set the **UnitPrice** lower limit to be any value greater than 0.0 as this means it has any price. The minimum value being 0.001. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extreme outliers in the lower and upper 1%\n",
    "\n",
    "# Get original length to see percent removed\n",
    "orig_tot = len(df)\n",
    "\n",
    "# Subset to remove extreme outliers\n",
    "# Quantity\n",
    "df = df[(df.Quantity > 0.0) & (df.Quantity <= 120.0)] \n",
    "# UnitPrice lot\n",
    "df = df[(df.UnitPrice > 0.0) & (df.UnitPrice <= 15.0)]\n",
    "\n",
    "# Calculate percent removed\n",
    "print('Percent removed:', (orig_tot -len(df))/orig_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw how removing the rows with Null **CustomerIDs** also removed the negative **UnitPrices**, I'm wondering if it would be best to remove the rows with negative Quantity value as well. We can see here with the 1% being -2.0, the 2% being -1.0 and the 2.5% being 1.0. \n",
    "\n",
    "I will keep it standard for now with percentiles, however it ma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems returns are extremely rare, which we can see with the **Quantity** 0.01 percentile being -2.0. I'm wondering if returns should be removed alltogether since they are rare, or if there are certain segments of customers who are more prone to returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df.Quantity)\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(df.UnitPrice)\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(df.TotalPrice)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df.Quantity)\n",
    "plt.show()\n",
    "sns.distplot(df.UnitPrice)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that removing the Null **CustomerID** data also removed all of the negative **UnitPrice** values. \n",
    "\n",
    "We can see visually there are some major outliers. With this data set it's easy to visually see the outliers, so I could remove them that way, however I'm going to remove them by removing the upper and lower percentiles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot\n",
    "sns.pairplot(df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
