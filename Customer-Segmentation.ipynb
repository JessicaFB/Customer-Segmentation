{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Intro\" data-toc-modified-id=\"Intro-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Intro</a></span></li><li><span><a href=\"#Import-Packages-+-Data\" data-toc-modified-id=\"Import-Packages-+-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Import Packages + Data</a></span></li><li><span><a href=\"#Explore-+-Clean-Data\" data-toc-modified-id=\"Explore-+-Clean-Data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Explore + Clean Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Check-For-Null-Values\" data-toc-modified-id=\"Check-For-Null-Values-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Check For Null Values</a></span></li><li><span><a href=\"#Check-For-Duplicates\" data-toc-modified-id=\"Check-For-Duplicates-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Check For Duplicates</a></span></li><li><span><a href=\"#Add-TotalPrice-Column\" data-toc-modified-id=\"Add-TotalPrice-Column-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Add TotalPrice Column</a></span></li><li><span><a href=\"#Remove-Outliers\" data-toc-modified-id=\"Remove-Outliers-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Remove Outliers</a></span></li></ul></li><li><span><a href=\"#Future-Work\" data-toc-modified-id=\"Future-Work-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Future Work</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "We're going to do an RFM analysis. RFM stands for Recency, Frequency and Monetary Value. We are then going to segment customers based on rankings in these three categories. We will use K-Means Clustering to segment the customers. By having these groups identified, we can target our marketing efforts with customers to increase revenue while retaining customers. (Add detail with this.)\n",
    "\n",
    "**Recency** is how recently a customer made a purchase. \n",
    "\n",
    "**Frequency** is how often a customer makes a purchase. \n",
    "\n",
    "**Monetary** Value represents the amount of money a customer spent in a given time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages + Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>536365</td>\n",
       "      <td>85123A</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>2.55</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>536365</td>\n",
       "      <td>71053</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>536365</td>\n",
       "      <td>84406B</td>\n",
       "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
       "      <td>8</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>536365</td>\n",
       "      <td>84029G</td>\n",
       "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>536365</td>\n",
       "      <td>84029E</td>\n",
       "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  InvoiceNo StockCode                          Description  Quantity  \\\n",
       "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
       "1    536365     71053                  WHITE METAL LANTERN         6   \n",
       "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
       "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
       "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
       "\n",
       "          InvoiceDate  UnitPrice  CustomerID         Country  \n",
       "0 2010-12-01 08:26:00       2.55     17850.0  United Kingdom  \n",
       "1 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
       "2 2010-12-01 08:26:00       2.75     17850.0  United Kingdom  \n",
       "3 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  \n",
       "4 2010-12-01 08:26:00       3.39     17850.0  United Kingdom  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data & convert to df\n",
    "data = pd.read_excel('Data/Online_Retail.xlsx')\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Preview\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here there are multiple items and quantities purchased on each invoice. I will create another column that shows total spent on each item, so Quantity * UnitPrice. That way we can group by invoice number, customer, etc. and see the total they spent per invoice and item.\n",
    "\n",
    "We're also going to be adding Recency, Frequency and Monetary columns so we can conduct an RMF analysis and segment customers that way as well. \n",
    "\n",
    "Let's take a look at some of the basics before we hop into it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore + Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 541909 entries, 0 to 541908\n",
      "Data columns (total 8 columns):\n",
      "InvoiceNo      541909 non-null object\n",
      "StockCode      541909 non-null object\n",
      "Description    540455 non-null object\n",
      "Quantity       541909 non-null int64\n",
      "InvoiceDate    541909 non-null datetime64[ns]\n",
      "UnitPrice      541909 non-null float64\n",
      "CustomerID     406829 non-null float64\n",
      "Country        541909 non-null object\n",
      "dtypes: datetime64[ns](1), float64(2), int64(1), object(4)\n",
      "memory usage: 33.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**InvoiceNo** is currently an object. I'm going to change that to an integer so we'll be able to group by invoice number. \n",
    "\n",
    "**StockCode** can stay an object, I'm guessing it's a string. \n",
    "\n",
    "It's great that **InvoiceDate** is already in datetime format, because we can peak at some time series in the EDA to see if we can collect any further insights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check For Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InvoiceNo           0\n",
       "StockCode           0\n",
       "Description      1454\n",
       "Quantity            0\n",
       "InvoiceDate         0\n",
       "UnitPrice           0\n",
       "CustomerID     135080\n",
       "Country             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we have a good amount of Null values for **CustomerID** and **Description**. Let's see how much of the total this accounts for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description Percent Null Values:\n",
      "0.2683 % \n",
      "\n",
      "CustomerID Percent Null Values:\n",
      "24.9267 % \n",
      "\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# Description\n",
    "print('Description Percent Null Values:')\n",
    "print(f\"{((df.Description.isnull().sum())/len(df.Description)*100).round(4)} % \\n\")\n",
    "\n",
    "# CustomerID\n",
    "print('CustomerID Percent Null Values:')\n",
    "print(f\"{((df.CustomerID.isnull().sum())/len(df.CustomerID)*100).round(4)} % \\n\")\n",
    "\n",
    "print('==============================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of missing values for the **Description** column is small, however for the **CustomerID** column it is large at almost 25%. I'm curious how many customers there were. Let's take a look at the number of unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of unique CustomerIDs: \n",
      "4372\n"
     ]
    }
   ],
   "source": [
    "# Unique CustomerIDs\n",
    "\n",
    "print(f'No. of unique CustomerIDs: \\n{len(df.CustomerID.value_counts())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we still have data from over 4,300 customers, and we don't have any way of identifying the customers with the Null **CustomerID** field, it only makes sense to remove them. \n",
    "\n",
    "Since this is an RMF Analysis, we don't require the product descriptions. However, for future work in identifying any trends of products and categories each group desires, we would require this information. For such an analysis we could impute or simply drop as it represents only a fraction of a percent of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows w/null fields\n",
    "df = df[df['CustomerID'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InvoiceNo      0\n",
       "StockCode      0\n",
       "Description    0\n",
       "Quantity       0\n",
       "InvoiceDate    0\n",
       "UnitPrice      0\n",
       "CustomerID     0\n",
       "Country        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like dropping the null CustomerID data also removed the null Descriptions data. Well that worked out perfectly. \n",
    "\n",
    "I'm curious if the nulls were from any particular country, as almost 25% of the data had nulls, this is a significant amount of data and does have the potential to skew "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check For Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df.duplicated()]\n",
    "df[df.InvoiceNo == 536412].duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[617:622]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of these seem to be duplicates, so we're going to leave these here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add TotalPrice Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TotalPrice'] = df['Quantity'] * df['UnitPrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explore this further. Are these isolated events of extremely high Quantity ordered and then returned?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.TotalPrice.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there are some major outliers in our dataset. Let's remove them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentiles for Quantity\n",
    "\n",
    "# Define percentiles\n",
    "percentiles = [0,2.5,97.5,100]\n",
    "\n",
    "# Print them out\n",
    "for i in percentiles:\n",
    "    q = i/100\n",
    "    print(\"{} percentile Quantity: {}\".format(q, df.Quantity.quantile(q=q)))\n",
    "    \n",
    "# Percentiles for UnitPrice\n",
    "\n",
    "# Print them out\n",
    "for i in percentiles:\n",
    "    q = i/100\n",
    "    print(\"{} percentile UnitPrice: {}\".format(q, df.UnitPrice.quantile(q=q)))\n",
    "    \n",
    "# Percentiles for TotalPrice\n",
    "\n",
    "# Print them out\n",
    "for i in percentiles:\n",
    "    q = i/100\n",
    "    print(\"{} percentile TotalPrice: {}\".format(q, df.TotalPrice.quantile(q=q)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to remove what may be returns or negative **Quantity** values as the lower 1% is -2.0 and the lower 2.5% was 1.0. We also removed all of the negative UnitPrice values when we removed the Null **CustomerID** values. \n",
    "\n",
    "We're also going to set the **UnitPrice** lower limit to be any value greater than 0.0 as this means it has any price. The minimum value being 0.001. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extreme outliers in the lower and upper 1%\n",
    "\n",
    "# Get original length to see percent removed\n",
    "orig_tot = len(df)\n",
    "\n",
    "# Subset to remove extreme outliers\n",
    "# Quantity\n",
    "df = df[(df.Quantity > 0.0) & (df.Quantity <= 120.0)] \n",
    "# UnitPrice lot\n",
    "df = df[(df.UnitPrice > 0.0) & (df.UnitPrice <= 15.0)]\n",
    "\n",
    "# Calculate percent removed\n",
    "print('Percent removed:', (orig_tot -len(df))/orig_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw how removing the rows with Null **CustomerIDs** also removed the negative **UnitPrices**, I'm wondering if it would be best to remove the rows with negative Quantity value as well. We can see here with the 1% being -2.0, the 2% being -1.0 and the 2.5% being 1.0. \n",
    "\n",
    "I will keep it standard for now with percentiles, however it ma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems returns are extremely rare, which we can see with the **Quantity** 0.01 percentile being -2.0. I'm wondering if returns should be removed alltogether since they are rare, or if there are certain segments of customers who are more prone to returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df.Quantity)\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(df.UnitPrice)\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(df.TotalPrice)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df.Quantity)\n",
    "plt.show()\n",
    "sns.distplot(df.UnitPrice)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that removing the Null **CustomerID** data also removed all of the negative **UnitPrice** values. \n",
    "\n",
    "We can see visually there are some major outliers. With this data set it's easy to visually see the outliers, so I could remove them that way, however I'm going to remove them by removing the upper and lower percentiles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Quantity','UnitPrice','TotalPrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot\n",
    "sns.pairplot(df[['Quantity','UnitPrice','TotalPrice']]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there appears to be a clear linear relationship between **TotalPrice** and **Quantity** and **TotalPrice** and **UnitPrice**, with no apparent relationship between **UnitPrice** and **Quantity**. This intuitively makes sense as **TotalPrice** is calculated as **Quantity * UnitPrice**. \n",
    "\n",
    "We could also take a look at a correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "\n",
    "df[['Quantity','UnitPrice','TotalPrice']].corr().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting that there is actually a weak correlation between **UnitPrice** and **TotalPrice** and a weak yet stronger than the former correlation between **UnitPrice** and **Quantity**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the **Country** data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique invoices\n",
    "len(df.InvoiceNo.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique invoices per country\n",
    "df.groupby(['Country'])['InvoiceNo'].nunique().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see most of the purchases are from the **United Kingdom**. We could model the UK exclusively, however since this is from an online retailer, I'm interested to see if there are similar groups across countries. \n",
    "\n",
    "We can always come back and model for the top country or countries (in terms of orders) if we find the model works better that way. \n",
    "\n",
    "On that note, I'm curious to see what types of items these customers are purchasing online. Let's take a look at the **Descriptions**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Description.value_counts(ascending=False)[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.Description.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3,833 unique descriptions. \n",
    "\n",
    "We can see there are a lot of lunch bags. I'm curious if it would be worth creating a category. Like **Description** = 'LUNCH BAG' then a different field with the specific type, or remove it alltogether. \n",
    "\n",
    "This wouldn't be as important for an RMF analysis with segmentation. However, for segmentation looking also at types of items purchased, this information would be valuable. \n",
    "\n",
    "Let's explore potential categories a bit more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Description.str.contains('LUNCH BAG') == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lot's of lunch bag purchases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Description.str.contains('LUNCH BAG') == True].Description.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like 'VINTAGE DOILEY' is meant to be 'VINTAGE DOILY'. I can correct that here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename to match category\n",
    "df.Description[df.Description == 'LUNCH BAG VINTAGE DOILEY '] = 'LUNCH BAG VINTAGE DOILY '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One customer purchased 40! I wonder what these are for. Businesses, parties, special events? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Description.str.contains('LUNCH BAG') == True].Description.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! We can see the 4 rows have been added. \n",
    "\n",
    "We can see there are more DOILY/DOILEY categories. I imagine these could all be combined. Let's keep looking and see what other products we have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.Description.str.contains('LUNCH BAG') != True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category of 'CHILDRENS CUTLERY'\n",
    "df[df.Description.str.contains('CHILDRENS CUTLERY') == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line called 'CIRCUS PARADE'\n",
    "df[df.Description.str.contains('CIRCUS PARADE') == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there are categories of the descriptions and also lines it appears. For example 'SPACE BOY', 'DOLLY GIRL', 'CIRCUS PARADE', etc. across multiple categories such as 'CHILDRENS CUTLERY', 'NAPKINS', 'APRON's and more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Description[df.Description.str.contains('CIRCUS PARADE') == True].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Description[df.Description.str.contains('PLASTERS IN TIN') == True].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Description[df.Description.str.contains('LUNCH BOX') == True].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Description[df.Description.str.contains('NAPKINS') == True].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Description[df.Description.str.contains('FAIRY CAKES') == True].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Description[df.Description.str.contains('NOTEBOOK') == True].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Description[df.Description.str.contains('BABUSHKA') == True].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Description[df.Description.str.contains('HOT WATER BOTTLE') == True].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Description[df.Description.str.contains('CHARLIE','LOLA') == True].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there are numerous different categories and lines of products. These could be broken down into categories and even colors for deeper insights and analyses. This would be a project in itself. For now I will continue to conduct an RMF analysis. However, for future work I believe it would be valuable to find groups of buyers based also on the types of categories they purchases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Work\n",
    "\n",
    "We can see there are many categories of products, such as napkins, aprons, notebooks, water bottles, lunch bags, etc. And across those categories there are many different lines of products, such as 'SPACE BOY', 'DOLLY GIRL', 'CIRCUS PARADE', 'CHARLIE + LOLA', and even 'BABUSHKA'. \n",
    "\n",
    "Greater insights could be attained by adding categories and lines. This could support more targeted advertising directly to its current customers, which would increase customer experience, engagement and revenue. It could also support targeted digital advertising such as Facebook and Google Ads. \n",
    "\n",
    "It the retailer doesn't already have it in place, they could add a recommendation system to increase price per transaction, revenue and customer lifetime values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
